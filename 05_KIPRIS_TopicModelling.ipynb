{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################\n",
    "<br> ######  Made by: Dr. Keungoui Kim \n",
    "<br> ######  Title: KISDI Megatrend Project - Data Prep 05. Topic Modelling\n",
    "<br> ######  goal : Megatrend Tech Analysis\n",
    "<br> ######  Data set: KIPRIS\n",
    "<br> ######  Time Span: \n",
    "<br> ######  Variables\n",
    "<br> ######  Input: \n",
    "<br> ######  Output: \n",
    "<br> ######  Methodology: \n",
    "<br> ######  Time-stamp: \n",
    "<br> ######  Notice :\n",
    "<br> #######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://christinarok.github.io/2021/04/08/mecab.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Google Drive(awekim@handong.edu)\\\\[Project]\\\\KISDI 과제\\\\02_메가트렌드'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85086, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>출원번호</th>\n",
       "      <th>type</th>\n",
       "      <th>초록</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1019910000249</td>\n",
       "      <td>플랫폼의 전방위적 확산</td>\n",
       "      <td>본 발명은 사전이나 백과사전과 같은 텍스트데이터가 기록되는 데이터디스크와 그 데이터...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1019910015464</td>\n",
       "      <td>플랫폼의 전방위적 확산</td>\n",
       "      <td>카드리더와 키보드를 이용하여 신용카드를 조회할 수 있는 시스템으로서, 통신포트를 선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1019920003044</td>\n",
       "      <td>플랫폼의 전방위적 확산</td>\n",
       "      <td>본 발명에서는 비교적 적은 수의 수용 가능 이미지를 합성하여 초기 판별함수를 형성함...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1019920010843</td>\n",
       "      <td>플랫폼의 전방위적 확산</td>\n",
       "      <td>어떤 상품을 선택할때 우리는 먼저 디자인과 색상을 살펴보고 이상적일때 다음으로 그제...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1019920012594</td>\n",
       "      <td>플랫폼의 전방위적 확산</td>\n",
       "      <td>본 발명은 상품을 판매하는 방법에 관한 것으로, 특히 주둔매점 판매형식을 일반화하여...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             출원번호          type  \\\n",
       "14  1019910000249  플랫폼의 전방위적 확산   \n",
       "17  1019910015464  플랫폼의 전방위적 확산   \n",
       "18  1019920003044  플랫폼의 전방위적 확산   \n",
       "21  1019920010843  플랫폼의 전방위적 확산   \n",
       "22  1019920012594  플랫폼의 전방위적 확산   \n",
       "\n",
       "                                                   초록  \n",
       "14  본 발명은 사전이나 백과사전과 같은 텍스트데이터가 기록되는 데이터디스크와 그 데이터...  \n",
       "17  카드리더와 키보드를 이용하여 신용카드를 조회할 수 있는 시스템으로서, 통신포트를 선...  \n",
       "18  본 발명에서는 비교적 적은 수의 수용 가능 이미지를 합성하여 초기 판별함수를 형성함...  \n",
       "21  어떤 상품을 선택할때 우리는 먼저 디자인과 색상을 살펴보고 이상적일때 다음으로 그제...  \n",
       "22  본 발명은 상품을 판매하는 방법에 관한 것으로, 특히 주둔매점 판매형식을 일반화하여...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Megatred_R/Abstract_trend.csv')\n",
    "data = data.loc[~data['초록'].isna()]\n",
    "data['type'] = data['type'].str.replace(': ', '-')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "플랫폼의 전방위적 확산\n",
      "자동화-노동 형태 다변화\n",
      "초개인화-맞춤화\n",
      "가상화-융합화\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "# okt = Okt()\n",
    "kkma = Kkma()\n",
    "\n",
    "postposition_patterns = [\n",
    "    r'을$', r'를$', r'이$', r'가$', r'은$', r'는$', r'의$', r'에$', r'에서$', r'로$', r'으로$', r'과$', r'와$', r'에 관한$', r'하다$', r'있다$', r'한다$', r'하는$', r'하여$'\n",
    "]\n",
    "\n",
    "stopwords = ['대한', '있다', '위한', '제1', '있습니다', '한다', '하는', '이것', '그것', '또는', '있음', '그리고', '하지만',\n",
    "             '관한', '있', '통해','상기','제2','관','티','위','포함','단계','발명']\n",
    "\n",
    "def preprocess_topics(topic_list):\n",
    "    cleaned_topics = []\n",
    "    for topic in topic_list:\n",
    "        words = topic.split(', ')\n",
    "        cleaned_words = []\n",
    "        for word in words:\n",
    "            for pattern in postposition_patterns:\n",
    "                word = re.sub(pattern, '', word)\n",
    "            if word not in stopwords and word and word not in cleaned_words:\n",
    "                cleaned_words.append(word)\n",
    "        cleaned_topics.append(cleaned_words)\n",
    "    return cleaned_topics\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = text.split(', ')\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        pos_tags = kkma.pos(word)\n",
    "        cleaned_words.extend([w for w, pos in pos_tags if pos in ['NNG', 'NNP'] and w not in stopwords])\n",
    "        # cleaned_words.extend([w for w, pos in pos_tags if pos not in ['JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'EF', 'EC']])\n",
    "    return list(set(cleaned_words))\n",
    "\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "### https://github.com/jhgan00/ko-sentence-transformers\n",
    "model = SentenceTransformer('jhgan/ko-sroberta-multitask') \n",
    "# MLP-KTLim/llama-3-Korean-Bllossom-8B, BM-K/KoSimCSE-roberta-multitask, xlm-r-bert-base-nli-stsb-mean-tokens\n",
    "# sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\n",
    "# snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
    "\n",
    "for i in list(data.type.unique()):\n",
    "    temp = data.loc[data.type==i]\n",
    "    documents = temp['초록']\n",
    "    documents\n",
    "    \n",
    "    preprocessed_docs = [doc for doc in documents]\n",
    "    \n",
    "    vectorizer_model = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "            embedding_model=model,\n",
    "            nr_topics=15,\n",
    "            min_topic_size=int(data['출원번호'].nunique()*0.005),\n",
    "            vectorizer_model=vectorizer_model,\n",
    "            ctfidf_model=ctfidf_model,\n",
    "            top_n_words = 20\n",
    "        )\n",
    "\n",
    "    topics, probs = topic_model.fit_transform(preprocessed_docs)\n",
    "    # topics = topic_model.reduce_outliers(preprocessed_docs, topics)\n",
    "    \n",
    "    topic_info = topic_model.get_topic_info()\n",
    "\n",
    "    topic_words = [topic_model.get_topic(topic) for topic in topic_info.Topic]\n",
    "    topic_words_ed = [', '.join([word for word, _ in words]) for words in topic_words]\n",
    "    \n",
    "    # cleaned_topics = preprocess_topics(topic_words_ed)\n",
    "    cleaned_topics = [preprocess_text(topic) for topic in topic_words_ed]\n",
    "    \n",
    "    # topic modelling results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Topic': topic_info['Topic'],\n",
    "        'Count': topic_info['Count'],\n",
    "        'Name': topic_info['Name'],\n",
    "        'Top Words': cleaned_topics #[', '.join([word for word, _ in words]) for words in topic_words]\n",
    "    })\n",
    "    result_df.to_csv('bertopic_results_'+str(i)+'.csv', index=False, encoding='utf-8-sig')\n",
    "      \n",
    "    # doc-topic label\n",
    "    df_docs = pd.DataFrame({\n",
    "    'Document': preprocessed_docs,\n",
    "    'Topic': topics\n",
    "    })\n",
    "    df_docs.to_csv('doc_topics_'+str(i)+'.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(i)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
